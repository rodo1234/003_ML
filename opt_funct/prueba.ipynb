{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T01:51:44.344266Z",
     "start_time": "2024-03-07T01:51:43.098851Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ta\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T01:51:44.349451Z",
     "start_time": "2024-03-07T01:51:44.348987Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_ds (df):\n",
    "    for i in range(1, 4):  \n",
    "        df[f'X_t-{i}'] = df['Close'].shift(i)\n",
    "\n",
    "    # Shift Close Column up by 5 rows\n",
    "    df['Pt_5'] = df['Close'].shift(-5)\n",
    "\n",
    "    #Agregamos RSI\n",
    "    rsi_data = ta.momentum.RSIIndicator(close= df['Close'], window=28)\n",
    "    df['RSI'] = rsi_data.rsi()\n",
    "\n",
    "    # La Y\n",
    "    df['Y_BUY'] = df['Close'] * (1 + 0.02) < df['Pt_5']\n",
    "    df['Y_SELL'] = df['Close'] * (1 - 0.02) > df['Pt_5']\n",
    "    \n",
    "    df['Y_BUY'] = df['Y_BUY'].astype(int)\n",
    "    df['Y_SELL'] = df['Y_SELL'].astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T01:51:44.366419Z",
     "start_time": "2024-03-07T01:51:44.349138Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      Timestamp  Gmtoffset             Datetime        Open        High  \\\n0    1602509400          0  2020-10-12 13:30:00  120.059997  121.330101   \n1    1602513000          0  2020-10-12 14:30:00  120.919998  122.639999   \n2    1602516600          0  2020-10-12 15:30:00  122.525001  123.629997   \n3    1602520200          0  2020-10-12 16:30:00  123.260002  124.000000   \n4    1602523800          0  2020-10-12 17:30:00  124.089996  125.180000   \n..          ...        ...                  ...         ...         ...   \n390  1609432200          0  2020-12-31 16:30:00  132.529998  132.800003   \n391  1609435800          0  2020-12-31 17:30:00  132.619995  132.717605   \n392  1609439400          0  2020-12-31 18:30:00  132.565002  132.889999   \n393  1609443000          0  2020-12-31 19:30:00  132.770004  133.179992   \n394  1609446600          0  2020-12-31 20:30:00  132.794998  133.330001   \n\n            Low       Close      Volume  \n0    119.284500  120.919998  48082766.0  \n1    120.769996  122.529998  27028067.0  \n2    122.290000  123.261001  35722193.0  \n3    123.040000  123.930000  22891159.0  \n4    123.910003  125.050003  31443470.0  \n..          ...         ...         ...  \n390  131.720001  132.619995  13538948.0  \n391  132.310104  132.560806   7474176.0  \n392  132.009994  132.764999   9408857.0  \n393  132.565994  132.800003  10147999.0  \n394  132.449996  132.580001  11777361.0  \n\n[395 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Timestamp</th>\n      <th>Gmtoffset</th>\n      <th>Datetime</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1602509400</td>\n      <td>0</td>\n      <td>2020-10-12 13:30:00</td>\n      <td>120.059997</td>\n      <td>121.330101</td>\n      <td>119.284500</td>\n      <td>120.919998</td>\n      <td>48082766.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1602513000</td>\n      <td>0</td>\n      <td>2020-10-12 14:30:00</td>\n      <td>120.919998</td>\n      <td>122.639999</td>\n      <td>120.769996</td>\n      <td>122.529998</td>\n      <td>27028067.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1602516600</td>\n      <td>0</td>\n      <td>2020-10-12 15:30:00</td>\n      <td>122.525001</td>\n      <td>123.629997</td>\n      <td>122.290000</td>\n      <td>123.261001</td>\n      <td>35722193.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1602520200</td>\n      <td>0</td>\n      <td>2020-10-12 16:30:00</td>\n      <td>123.260002</td>\n      <td>124.000000</td>\n      <td>123.040000</td>\n      <td>123.930000</td>\n      <td>22891159.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1602523800</td>\n      <td>0</td>\n      <td>2020-10-12 17:30:00</td>\n      <td>124.089996</td>\n      <td>125.180000</td>\n      <td>123.910003</td>\n      <td>125.050003</td>\n      <td>31443470.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>390</th>\n      <td>1609432200</td>\n      <td>0</td>\n      <td>2020-12-31 16:30:00</td>\n      <td>132.529998</td>\n      <td>132.800003</td>\n      <td>131.720001</td>\n      <td>132.619995</td>\n      <td>13538948.0</td>\n    </tr>\n    <tr>\n      <th>391</th>\n      <td>1609435800</td>\n      <td>0</td>\n      <td>2020-12-31 17:30:00</td>\n      <td>132.619995</td>\n      <td>132.717605</td>\n      <td>132.310104</td>\n      <td>132.560806</td>\n      <td>7474176.0</td>\n    </tr>\n    <tr>\n      <th>392</th>\n      <td>1609439400</td>\n      <td>0</td>\n      <td>2020-12-31 18:30:00</td>\n      <td>132.565002</td>\n      <td>132.889999</td>\n      <td>132.009994</td>\n      <td>132.764999</td>\n      <td>9408857.0</td>\n    </tr>\n    <tr>\n      <th>393</th>\n      <td>1609443000</td>\n      <td>0</td>\n      <td>2020-12-31 19:30:00</td>\n      <td>132.770004</td>\n      <td>133.179992</td>\n      <td>132.565994</td>\n      <td>132.800003</td>\n      <td>10147999.0</td>\n    </tr>\n    <tr>\n      <th>394</th>\n      <td>1609446600</td>\n      <td>0</td>\n      <td>2020-12-31 20:30:00</td>\n      <td>132.794998</td>\n      <td>133.330001</td>\n      <td>132.449996</td>\n      <td>132.580001</td>\n      <td>11777361.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>395 rows Ã— 8 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1 = pd.read_csv('../data/aapl_1h_train.csv')\n",
    "data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T01:51:44.380470Z",
     "start_time": "2024-03-07T01:51:44.366915Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      Timestamp  Gmtoffset             Datetime        Open        High  \\\n0    1602509400          0  2020-10-12 13:30:00  120.059997  121.330101   \n1    1602513000          0  2020-10-12 14:30:00  120.919998  122.639999   \n2    1602516600          0  2020-10-12 15:30:00  122.525001  123.629997   \n3    1602520200          0  2020-10-12 16:30:00  123.260002  124.000000   \n4    1602523800          0  2020-10-12 17:30:00  124.089996  125.180000   \n..          ...        ...                  ...         ...         ...   \n390  1609432200          0  2020-12-31 16:30:00  132.529998  132.800003   \n391  1609435800          0  2020-12-31 17:30:00  132.619995  132.717605   \n392  1609439400          0  2020-12-31 18:30:00  132.565002  132.889999   \n393  1609443000          0  2020-12-31 19:30:00  132.770004  133.179992   \n394  1609446600          0  2020-12-31 20:30:00  132.794998  133.330001   \n\n            Low       Close      Volume       X_t-1       X_t-2       X_t-3  \\\n0    119.284500  120.919998  48082766.0         NaN         NaN         NaN   \n1    120.769996  122.529998  27028067.0  120.919998         NaN         NaN   \n2    122.290000  123.261001  35722193.0  122.529998  120.919998         NaN   \n3    123.040000  123.930000  22891159.0  123.261001  122.529998  120.919998   \n4    123.910003  125.050003  31443470.0  123.930000  123.261001  122.529998   \n..          ...         ...         ...         ...         ...         ...   \n390  131.720001  132.619995  13538948.0  132.529998  132.884994  133.679992   \n391  132.310104  132.560806   7474176.0  132.619995  132.529998  132.884994   \n392  132.009994  132.764999   9408857.0  132.560806  132.619995  132.529998   \n393  132.565994  132.800003  10147999.0  132.764999  132.560806  132.619995   \n394  132.449996  132.580001  11777361.0  132.800003  132.764999  132.560806   \n\n           Pt_5        RSI  Y_BUY  Y_SELL  \n0    124.314102        NaN      1       0  \n1    124.419998        NaN      0       0  \n2    123.757202        NaN      0       0  \n3    124.430000        NaN      0       0  \n4    123.080001        NaN      0       0  \n..          ...        ...    ...     ...  \n390         NaN  50.983206      0       0  \n391         NaN  50.783652      0       0  \n392         NaN  51.463321      0       0  \n393         NaN  51.582189      0       0  \n394         NaN  50.771752      0       0  \n\n[395 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Timestamp</th>\n      <th>Gmtoffset</th>\n      <th>Datetime</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Volume</th>\n      <th>X_t-1</th>\n      <th>X_t-2</th>\n      <th>X_t-3</th>\n      <th>Pt_5</th>\n      <th>RSI</th>\n      <th>Y_BUY</th>\n      <th>Y_SELL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1602509400</td>\n      <td>0</td>\n      <td>2020-10-12 13:30:00</td>\n      <td>120.059997</td>\n      <td>121.330101</td>\n      <td>119.284500</td>\n      <td>120.919998</td>\n      <td>48082766.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>124.314102</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1602513000</td>\n      <td>0</td>\n      <td>2020-10-12 14:30:00</td>\n      <td>120.919998</td>\n      <td>122.639999</td>\n      <td>120.769996</td>\n      <td>122.529998</td>\n      <td>27028067.0</td>\n      <td>120.919998</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>124.419998</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1602516600</td>\n      <td>0</td>\n      <td>2020-10-12 15:30:00</td>\n      <td>122.525001</td>\n      <td>123.629997</td>\n      <td>122.290000</td>\n      <td>123.261001</td>\n      <td>35722193.0</td>\n      <td>122.529998</td>\n      <td>120.919998</td>\n      <td>NaN</td>\n      <td>123.757202</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1602520200</td>\n      <td>0</td>\n      <td>2020-10-12 16:30:00</td>\n      <td>123.260002</td>\n      <td>124.000000</td>\n      <td>123.040000</td>\n      <td>123.930000</td>\n      <td>22891159.0</td>\n      <td>123.261001</td>\n      <td>122.529998</td>\n      <td>120.919998</td>\n      <td>124.430000</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1602523800</td>\n      <td>0</td>\n      <td>2020-10-12 17:30:00</td>\n      <td>124.089996</td>\n      <td>125.180000</td>\n      <td>123.910003</td>\n      <td>125.050003</td>\n      <td>31443470.0</td>\n      <td>123.930000</td>\n      <td>123.261001</td>\n      <td>122.529998</td>\n      <td>123.080001</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>390</th>\n      <td>1609432200</td>\n      <td>0</td>\n      <td>2020-12-31 16:30:00</td>\n      <td>132.529998</td>\n      <td>132.800003</td>\n      <td>131.720001</td>\n      <td>132.619995</td>\n      <td>13538948.0</td>\n      <td>132.529998</td>\n      <td>132.884994</td>\n      <td>133.679992</td>\n      <td>NaN</td>\n      <td>50.983206</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>391</th>\n      <td>1609435800</td>\n      <td>0</td>\n      <td>2020-12-31 17:30:00</td>\n      <td>132.619995</td>\n      <td>132.717605</td>\n      <td>132.310104</td>\n      <td>132.560806</td>\n      <td>7474176.0</td>\n      <td>132.619995</td>\n      <td>132.529998</td>\n      <td>132.884994</td>\n      <td>NaN</td>\n      <td>50.783652</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>392</th>\n      <td>1609439400</td>\n      <td>0</td>\n      <td>2020-12-31 18:30:00</td>\n      <td>132.565002</td>\n      <td>132.889999</td>\n      <td>132.009994</td>\n      <td>132.764999</td>\n      <td>9408857.0</td>\n      <td>132.560806</td>\n      <td>132.619995</td>\n      <td>132.529998</td>\n      <td>NaN</td>\n      <td>51.463321</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>393</th>\n      <td>1609443000</td>\n      <td>0</td>\n      <td>2020-12-31 19:30:00</td>\n      <td>132.770004</td>\n      <td>133.179992</td>\n      <td>132.565994</td>\n      <td>132.800003</td>\n      <td>10147999.0</td>\n      <td>132.764999</td>\n      <td>132.560806</td>\n      <td>132.619995</td>\n      <td>NaN</td>\n      <td>51.582189</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>394</th>\n      <td>1609446600</td>\n      <td>0</td>\n      <td>2020-12-31 20:30:00</td>\n      <td>132.794998</td>\n      <td>133.330001</td>\n      <td>132.449996</td>\n      <td>132.580001</td>\n      <td>11777361.0</td>\n      <td>132.800003</td>\n      <td>132.764999</td>\n      <td>132.560806</td>\n      <td>NaN</td>\n      <td>50.771752</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>395 rows Ã— 15 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ejem = clean_ds(data_1)\n",
    "data_ejem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T01:51:44.400730Z",
     "start_time": "2024-03-07T01:51:44.379976Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          Close       X_t-1       X_t-2       X_t-3        RSI  Y_BUY\n0    120.919998         NaN         NaN         NaN        NaN      1\n1    122.529998  120.919998         NaN         NaN        NaN      0\n2    123.261001  122.529998  120.919998         NaN        NaN      0\n3    123.930000  123.261001  122.529998  120.919998        NaN      0\n4    125.050003  123.930000  123.261001  122.529998        NaN      0\n..          ...         ...         ...         ...        ...    ...\n390  132.619995  132.529998  132.884994  133.679992  50.983206      0\n391  132.560806  132.619995  132.529998  132.884994  50.783652      0\n392  132.764999  132.560806  132.619995  132.529998  51.463321      0\n393  132.800003  132.764999  132.560806  132.619995  51.582189      0\n394  132.580001  132.800003  132.764999  132.560806  50.771752      0\n\n[395 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Close</th>\n      <th>X_t-1</th>\n      <th>X_t-2</th>\n      <th>X_t-3</th>\n      <th>RSI</th>\n      <th>Y_BUY</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>120.919998</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>122.529998</td>\n      <td>120.919998</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>123.261001</td>\n      <td>122.529998</td>\n      <td>120.919998</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>123.930000</td>\n      <td>123.261001</td>\n      <td>122.529998</td>\n      <td>120.919998</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>125.050003</td>\n      <td>123.930000</td>\n      <td>123.261001</td>\n      <td>122.529998</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>390</th>\n      <td>132.619995</td>\n      <td>132.529998</td>\n      <td>132.884994</td>\n      <td>133.679992</td>\n      <td>50.983206</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>391</th>\n      <td>132.560806</td>\n      <td>132.619995</td>\n      <td>132.529998</td>\n      <td>132.884994</td>\n      <td>50.783652</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>392</th>\n      <td>132.764999</td>\n      <td>132.560806</td>\n      <td>132.619995</td>\n      <td>132.529998</td>\n      <td>51.463321</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>393</th>\n      <td>132.800003</td>\n      <td>132.764999</td>\n      <td>132.560806</td>\n      <td>132.619995</td>\n      <td>51.582189</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>394</th>\n      <td>132.580001</td>\n      <td>132.800003</td>\n      <td>132.764999</td>\n      <td>132.560806</td>\n      <td>50.771752</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>395 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close_data = data_ejem[['Close', 'X_t-1', 'X_t-2', 'X_t-3', 'RSI', 'Y_BUY']]\n",
    "close_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T01:51:44.426175Z",
     "start_time": "2024-03-07T01:51:44.384564Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Y_BUY\n0    359\n1     36\nName: count, dtype: int64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close_data['Y_BUY'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T01:51:44.426582Z",
     "start_time": "2024-03-07T01:51:44.387406Z"
    }
   },
   "outputs": [],
   "source": [
    "x = close_data.drop(columns=['Y_BUY'])\n",
    "y = close_data[['Y_BUY']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T01:51:44.426641Z",
     "start_time": "2024-03-07T01:51:44.389404Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T01:51:44.431367Z",
     "start_time": "2024-03-07T01:51:44.391251Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T01:51:44.440238Z",
     "start_time": "2024-03-07T01:51:44.396580Z"
    }
   },
   "outputs": [],
   "source": [
    "class XGBOptimizer:\n",
    "    def __init__(self, x_train, y_train, x_test, y_test):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "\n",
    "    def opt_xgb(self, trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'max_leaves': trial.suggest_int('max_leaves', 3, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "            'booster': trial.suggest_categorical('booster', ['gbtree', 'gblinear', 'dart']),\n",
    "            'gamma': trial.suggest_float('gamma', 0.1, 1),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0.1, 1),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 0.1, 1),\n",
    "            'eval_metric': 'logloss',  \n",
    "            'use_label_encoder': False,\n",
    "            'device': 'cuda' # Si no tienen GPU y linux comentar esta linea\n",
    "        }\n",
    "        model = xgb.XGBClassifier(**params)\n",
    "        model.fit(self.x_train, self.y_train)\n",
    "        y_pred = model.predict(self.x_test)\n",
    "        f1 = f1_score(self.y_test, y_pred)\n",
    "        return f1\n",
    "\n",
    "    def xgb_optuna(self):\n",
    "        start_time = time.time()\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(lambda trial: self.opt_xgb(trial), n_trials=100)\n",
    "        trial = study.best_trial\n",
    "        print('Accuracy: {}'.format(trial.value))\n",
    "        print(\"Best hyperparameters: {}\".format(trial.params))\n",
    "        end_time = time.time()\n",
    "        execution_time_minutes = (end_time - start_time) / 60\n",
    "        print(\"Execution time: {} minutes\".format(execution_time_minutes))\n",
    "        return trial.params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T01:53:32.541039Z",
     "start_time": "2024-03-07T01:51:44.398573Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-06 19:51:44,398] A new study created in memory with name: no-name-bd161412-3b41-423b-ab6f-d6b36a4ed3aa\n",
      "[I 2024-03-06 19:51:44,442] Trial 0 finished with value: 0.0 and parameters: {'n_estimators': 126, 'max_depth': 8, 'max_leaves': 7, 'learning_rate': 0.23811969682644046, 'booster': 'gbtree', 'gamma': 0.5858818769373417, 'reg_alpha': 0.2303850918748473, 'reg_lambda': 0.8482876059976411}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:51:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:51:44,526] Trial 1 finished with value: 0.0 and parameters: {'n_estimators': 727, 'max_depth': 8, 'max_leaves': 10, 'learning_rate': 0.030266685515556776, 'booster': 'gblinear', 'gamma': 0.7102025655031942, 'reg_alpha': 0.18293053121007216, 'reg_lambda': 0.29965587066894717}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:51:44,601] Trial 2 finished with value: 0.0 and parameters: {'n_estimators': 303, 'max_depth': 5, 'max_leaves': 7, 'learning_rate': 0.12227754611086561, 'booster': 'gbtree', 'gamma': 0.27398223524015636, 'reg_alpha': 0.6148283592442901, 'reg_lambda': 0.3850042006629351}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:51:44,840] Trial 3 finished with value: 0.0 and parameters: {'n_estimators': 932, 'max_depth': 4, 'max_leaves': 10, 'learning_rate': 0.11220076409260687, 'booster': 'gbtree', 'gamma': 0.5095913370739001, 'reg_alpha': 0.7738787803757577, 'reg_lambda': 0.3083573049180398}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:51:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:51:44,930] Trial 4 finished with value: 0.0 and parameters: {'n_estimators': 733, 'max_depth': 6, 'max_leaves': 5, 'learning_rate': 0.03287172646579424, 'booster': 'gblinear', 'gamma': 0.6489291139176621, 'reg_alpha': 0.9664715345628021, 'reg_lambda': 0.24685592753976346}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:51:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:51:44,963] Trial 5 finished with value: 0.0 and parameters: {'n_estimators': 308, 'max_depth': 7, 'max_leaves': 3, 'learning_rate': 0.13565256253146968, 'booster': 'gblinear', 'gamma': 0.17379087169538518, 'reg_alpha': 0.642463502546832, 'reg_lambda': 0.39928503534759513}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:51:45,094] Trial 6 finished with value: 0.0 and parameters: {'n_estimators': 508, 'max_depth': 6, 'max_leaves': 9, 'learning_rate': 0.12384737718750205, 'booster': 'gbtree', 'gamma': 0.6072231445276056, 'reg_alpha': 0.7021722818711225, 'reg_lambda': 0.5060245675782564}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:51:45,139] Trial 7 finished with value: 0.0 and parameters: {'n_estimators': 199, 'max_depth': 8, 'max_leaves': 5, 'learning_rate': 0.1512887231220461, 'booster': 'gbtree', 'gamma': 0.4446278313967164, 'reg_alpha': 0.8249063843390717, 'reg_lambda': 0.49664412411076386}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:51:45,266] Trial 8 finished with value: 0.0 and parameters: {'n_estimators': 988, 'max_depth': 9, 'max_leaves': 5, 'learning_rate': 0.19454132064971327, 'booster': 'gbtree', 'gamma': 0.4984156787897598, 'reg_alpha': 0.36010676084475945, 'reg_lambda': 0.8513761259026997}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:51:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:51:45,281] Trial 9 finished with value: 0.0 and parameters: {'n_estimators': 160, 'max_depth': 9, 'max_leaves': 10, 'learning_rate': 0.20426544467660812, 'booster': 'gblinear', 'gamma': 0.5337854339295722, 'reg_alpha': 0.2802450191050809, 'reg_lambda': 0.42749856672814796}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:51:50,396] Trial 10 finished with value: 0.0 and parameters: {'n_estimators': 475, 'max_depth': 10, 'max_leaves': 7, 'learning_rate': 0.27565991444027393, 'booster': 'dart', 'gamma': 0.980961468404816, 'reg_alpha': 0.43588559930600584, 'reg_lambda': 0.8474389048260318}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:03,106] Trial 11 finished with value: 0.0 and parameters: {'n_estimators': 784, 'max_depth': 8, 'max_leaves': 8, 'learning_rate': 0.047297745206658595, 'booster': 'dart', 'gamma': 0.7926357107909506, 'reg_alpha': 0.1076515013787623, 'reg_lambda': 0.6637060493830471}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:52:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:52:03,178] Trial 12 finished with value: 0.0 and parameters: {'n_estimators': 656, 'max_depth': 7, 'max_leaves': 8, 'learning_rate': 0.2990903792009869, 'booster': 'gblinear', 'gamma': 0.7831927023487425, 'reg_alpha': 0.12244779701657527, 'reg_lambda': 0.13508117754880572}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:52:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:52:03,229] Trial 13 finished with value: 0.0 and parameters: {'n_estimators': 621, 'max_depth': 3, 'max_leaves': 9, 'learning_rate': 0.24546973186587095, 'booster': 'gblinear', 'gamma': 0.7832188111057035, 'reg_alpha': 0.24738335607980827, 'reg_lambda': 0.7586258149930913}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:16,958] Trial 14 finished with value: 0.0 and parameters: {'n_estimators': 841, 'max_depth': 10, 'max_leaves': 3, 'learning_rate': 0.07375713595441229, 'booster': 'dart', 'gamma': 0.9692545682619997, 'reg_alpha': 0.4614228667961253, 'reg_lambda': 0.9753047121102385}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:17,015] Trial 15 finished with value: 0.0 and parameters: {'n_estimators': 378, 'max_depth': 8, 'max_leaves': 6, 'learning_rate': 0.20866231479088218, 'booster': 'gbtree', 'gamma': 0.35000458091129655, 'reg_alpha': 0.2298022742997682, 'reg_lambda': 0.648018618768253}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:52:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:52:17,038] Trial 16 finished with value: 0.0 and parameters: {'n_estimators': 106, 'max_depth': 9, 'max_leaves': 9, 'learning_rate': 0.013466256474484545, 'booster': 'gblinear', 'gamma': 0.6622314626744149, 'reg_alpha': 0.4772915580069862, 'reg_lambda': 0.15481220631968995}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:52:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:52:17,088] Trial 17 finished with value: 0.0 and parameters: {'n_estimators': 615, 'max_depth': 7, 'max_leaves': 6, 'learning_rate': 0.23579676012740056, 'booster': 'gblinear', 'gamma': 0.7315501595704945, 'reg_alpha': 0.33089671430669176, 'reg_lambda': 0.5977899898752548}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:17,149] Trial 18 finished with value: 0.0 and parameters: {'n_estimators': 442, 'max_depth': 5, 'max_leaves': 8, 'learning_rate': 0.07916689915693251, 'booster': 'gbtree', 'gamma': 0.8986051808079142, 'reg_alpha': 0.17564823777660443, 'reg_lambda': 0.24517456691556727}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:31,349] Trial 19 finished with value: 0.0 and parameters: {'n_estimators': 860, 'max_depth': 8, 'max_leaves': 4, 'learning_rate': 0.17401142465146763, 'booster': 'dart', 'gamma': 0.40797836185455993, 'reg_alpha': 0.33162340955167036, 'reg_lambda': 0.9177797899844177}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:31,430] Trial 20 finished with value: 0.0 and parameters: {'n_estimators': 707, 'max_depth': 9, 'max_leaves': 10, 'learning_rate': 0.2444816584805197, 'booster': 'gbtree', 'gamma': 0.8641189992228421, 'reg_alpha': 0.5572973459213987, 'reg_lambda': 0.7437102312450223}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:31,485] Trial 21 finished with value: 0.0 and parameters: {'n_estimators': 270, 'max_depth': 5, 'max_leaves': 7, 'learning_rate': 0.08677499641338886, 'booster': 'gbtree', 'gamma': 0.2773259110463486, 'reg_alpha': 0.6288735208664792, 'reg_lambda': 0.3634588975816385}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:31,533] Trial 22 finished with value: 0.0 and parameters: {'n_estimators': 241, 'max_depth': 5, 'max_leaves': 7, 'learning_rate': 0.16744012163389177, 'booster': 'gbtree', 'gamma': 0.11990834754341265, 'reg_alpha': 0.40191012074519833, 'reg_lambda': 0.2878102100842036}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:31,613] Trial 23 finished with value: 0.0 and parameters: {'n_estimators': 357, 'max_depth': 6, 'max_leaves': 6, 'learning_rate': 0.04926634211438594, 'booster': 'gbtree', 'gamma': 0.26338235570389995, 'reg_alpha': 0.5398749255758427, 'reg_lambda': 0.4718697003673181}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:31,648] Trial 24 finished with value: 0.0 and parameters: {'n_estimators': 117, 'max_depth': 4, 'max_leaves': 8, 'learning_rate': 0.09298569489566441, 'booster': 'gbtree', 'gamma': 0.5803907711238087, 'reg_alpha': 0.18681512811679332, 'reg_lambda': 0.3601998350649266}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:52:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:52:31,702] Trial 25 finished with value: 0.0 and parameters: {'n_estimators': 551, 'max_depth': 7, 'max_leaves': 7, 'learning_rate': 0.10361386661537023, 'booster': 'gblinear', 'gamma': 0.6997383214963155, 'reg_alpha': 0.5403057514840637, 'reg_lambda': 0.5702004159434897}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:31,751] Trial 26 finished with value: 0.0 and parameters: {'n_estimators': 208, 'max_depth': 4, 'max_leaves': 9, 'learning_rate': 0.14173822559962737, 'booster': 'gbtree', 'gamma': 0.34845059354184693, 'reg_alpha': 0.8066343319638738, 'reg_lambda': 0.2031947446850705}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:31,842] Trial 27 finished with value: 0.0 and parameters: {'n_estimators': 348, 'max_depth': 3, 'max_leaves': 6, 'learning_rate': 0.011205236992041654, 'booster': 'gbtree', 'gamma': 0.4466088844956373, 'reg_alpha': 0.2804243640222304, 'reg_lambda': 0.30193503726196086}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:32,387] Trial 28 finished with value: 0.0 and parameters: {'n_estimators': 161, 'max_depth': 8, 'max_leaves': 4, 'learning_rate': 0.06266090800740283, 'booster': 'dart', 'gamma': 0.24077602641520834, 'reg_alpha': 0.9945856956623798, 'reg_lambda': 0.44015164117138994}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:52:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:52:32,431] Trial 29 finished with value: 0.0 and parameters: {'n_estimators': 396, 'max_depth': 5, 'max_leaves': 10, 'learning_rate': 0.174147294603962, 'booster': 'gblinear', 'gamma': 0.5143988189288728, 'reg_alpha': 0.6966364544072426, 'reg_lambda': 0.3473294473749886}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:32,516] Trial 30 finished with value: 0.0 and parameters: {'n_estimators': 560, 'max_depth': 6, 'max_leaves': 8, 'learning_rate': 0.11218053761074998, 'booster': 'gbtree', 'gamma': 0.6137487339152493, 'reg_alpha': 0.1711180229708886, 'reg_lambda': 0.7449667355662113}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:32,617] Trial 31 finished with value: 0.0 and parameters: {'n_estimators': 986, 'max_depth': 4, 'max_leaves': 10, 'learning_rate': 0.11836555121668609, 'booster': 'gbtree', 'gamma': 0.6917921927985261, 'reg_alpha': 0.8757428457448186, 'reg_lambda': 0.22027630242006602}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:32,748] Trial 32 finished with value: 0.0 and parameters: {'n_estimators': 915, 'max_depth': 3, 'max_leaves': 9, 'learning_rate': 0.028340950292306627, 'booster': 'gbtree', 'gamma': 0.3622552490296062, 'reg_alpha': 0.9243250136114289, 'reg_lambda': 0.3364150700451158}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:32,843] Trial 33 finished with value: 0.0 and parameters: {'n_estimators': 751, 'max_depth': 4, 'max_leaves': 10, 'learning_rate': 0.12963052331996944, 'booster': 'gbtree', 'gamma': 0.6251128741308604, 'reg_alpha': 0.7960000891697518, 'reg_lambda': 0.30130416583825803}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:52:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:52:32,882] Trial 34 finished with value: 0.0 and parameters: {'n_estimators': 290, 'max_depth': 7, 'max_leaves': 9, 'learning_rate': 0.15443090689623418, 'booster': 'gblinear', 'gamma': 0.20112259824456952, 'reg_alpha': 0.7230017184528965, 'reg_lambda': 0.4119279101889236}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:32,982] Trial 35 finished with value: 0.0 and parameters: {'n_estimators': 914, 'max_depth': 6, 'max_leaves': 5, 'learning_rate': 0.22365104233030725, 'booster': 'gbtree', 'gamma': 0.5637118976800198, 'reg_alpha': 0.6505781581378793, 'reg_lambda': 0.1923291943069038}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:33,065] Trial 36 finished with value: 0.0 and parameters: {'n_estimators': 691, 'max_depth': 5, 'max_leaves': 10, 'learning_rate': 0.18639387223756643, 'booster': 'gbtree', 'gamma': 0.4757313077023313, 'reg_alpha': 0.7536272976522894, 'reg_lambda': 0.5337652838543135}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:52:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:52:33,131] Trial 37 finished with value: 0.0 and parameters: {'n_estimators': 810, 'max_depth': 9, 'max_leaves': 7, 'learning_rate': 0.27574804539093467, 'booster': 'gblinear', 'gamma': 0.14190847484704083, 'reg_alpha': 0.5904063490008424, 'reg_lambda': 0.26826515703079373}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:33,229] Trial 38 finished with value: 0.0 and parameters: {'n_estimators': 908, 'max_depth': 6, 'max_leaves': 4, 'learning_rate': 0.13994986823901115, 'booster': 'gbtree', 'gamma': 0.5513894993884609, 'reg_alpha': 0.8894802139639093, 'reg_lambda': 0.475014900154068}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:52:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:52:33,277] Trial 39 finished with value: 0.0 and parameters: {'n_estimators': 446, 'max_depth': 4, 'max_leaves': 8, 'learning_rate': 0.10178945980144352, 'booster': 'gblinear', 'gamma': 0.7383737449558965, 'reg_alpha': 0.6656004127411382, 'reg_lambda': 0.39696471898375274}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:39,339] Trial 40 finished with value: 0.0 and parameters: {'n_estimators': 509, 'max_depth': 7, 'max_leaves': 5, 'learning_rate': 0.057651372162318165, 'booster': 'dart', 'gamma': 0.8611966374814886, 'reg_alpha': 0.41152014347215765, 'reg_lambda': 0.8140210390892281}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:52:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:52:39,430] Trial 41 finished with value: 0.0 and parameters: {'n_estimators': 757, 'max_depth': 6, 'max_leaves': 3, 'learning_rate': 0.03479979196446899, 'booster': 'gblinear', 'gamma': 0.6244300857183892, 'reg_alpha': 0.9974523122799129, 'reg_lambda': 0.17642319893909203}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:52:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:52:39,499] Trial 42 finished with value: 0.0 and parameters: {'n_estimators': 717, 'max_depth': 8, 'max_leaves': 6, 'learning_rate': 0.0290292394785525, 'booster': 'gblinear', 'gamma': 0.664811549860548, 'reg_alpha': 0.9333165824333569, 'reg_lambda': 0.10927661608463457}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:52:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:52:39,576] Trial 43 finished with value: 0.0 and parameters: {'n_estimators': 599, 'max_depth': 5, 'max_leaves': 5, 'learning_rate': 0.07506777771512342, 'booster': 'gblinear', 'gamma': 0.7532519864664866, 'reg_alpha': 0.8415233811399216, 'reg_lambda': 0.2277329800846049}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:52:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:52:39,668] Trial 44 finished with value: 0.0 and parameters: {'n_estimators': 854, 'max_depth': 8, 'max_leaves': 7, 'learning_rate': 0.044446573852996114, 'booster': 'gblinear', 'gamma': 0.47819280288102906, 'reg_alpha': 0.5929523747687374, 'reg_lambda': 0.2602948772514548}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:52:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:52:39,870] Trial 45 finished with value: 0.0 and parameters: {'n_estimators': 990, 'max_depth': 9, 'max_leaves': 9, 'learning_rate': 0.12497505773270287, 'booster': 'gblinear', 'gamma': 0.4128089200730107, 'reg_alpha': 0.10559865571834648, 'reg_lambda': 0.39579192231605087}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:39,965] Trial 46 finished with value: 0.0 and parameters: {'n_estimators': 662, 'max_depth': 10, 'max_leaves': 5, 'learning_rate': 0.2649042103493265, 'booster': 'gbtree', 'gamma': 0.6654694785802185, 'reg_alpha': 0.47374580495879187, 'reg_lambda': 0.9534175375596211}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:40,077] Trial 47 finished with value: 0.0 and parameters: {'n_estimators': 795, 'max_depth': 7, 'max_leaves': 9, 'learning_rate': 0.19499992971400787, 'booster': 'gbtree', 'gamma': 0.7982151645923622, 'reg_alpha': 0.76345304540112, 'reg_lambda': 0.6719398358579826}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:40,824] Trial 48 finished with value: 0.0 and parameters: {'n_estimators': 166, 'max_depth': 6, 'max_leaves': 8, 'learning_rate': 0.06396366225982872, 'booster': 'dart', 'gamma': 0.582949309577096, 'reg_alpha': 0.28041729985517355, 'reg_lambda': 0.33098353021522015}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:52:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:52:40,890] Trial 49 finished with value: 0.0 and parameters: {'n_estimators': 486, 'max_depth': 8, 'max_leaves': 10, 'learning_rate': 0.22287528951680333, 'booster': 'gblinear', 'gamma': 0.5152329207897782, 'reg_alpha': 0.2246277666243105, 'reg_lambda': 0.15451832627728052}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:40,957] Trial 50 finished with value: 0.0 and parameters: {'n_estimators': 318, 'max_depth': 5, 'max_leaves': 4, 'learning_rate': 0.29834253175543646, 'booster': 'gbtree', 'gamma': 0.3105010847239905, 'reg_alpha': 0.3643015250498003, 'reg_lambda': 0.5234189543172852}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:52:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:52:40,996] Trial 51 finished with value: 0.0 and parameters: {'n_estimators': 216, 'max_depth': 7, 'max_leaves': 3, 'learning_rate': 0.14158507022182332, 'booster': 'gblinear', 'gamma': 0.17250884476720302, 'reg_alpha': 0.5040569441796553, 'reg_lambda': 0.45101689117298516}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:52:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:52:41,083] Trial 52 finished with value: 0.0 and parameters: {'n_estimators': 416, 'max_depth': 8, 'max_leaves': 6, 'learning_rate': 0.16033078283101704, 'booster': 'gblinear', 'gamma': 0.22809962873338757, 'reg_alpha': 0.6142771015655009, 'reg_lambda': 0.3714326973279124}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:52:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:52:41,110] Trial 53 finished with value: 0.0 and parameters: {'n_estimators': 111, 'max_depth': 9, 'max_leaves': 3, 'learning_rate': 0.0852734565843232, 'booster': 'gblinear', 'gamma': 0.17476964289879957, 'reg_alpha': 0.6760662288560371, 'reg_lambda': 0.31015822866961046}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:52:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:52:41,154] Trial 54 finished with value: 0.0 and parameters: {'n_estimators': 290, 'max_depth': 7, 'max_leaves': 4, 'learning_rate': 0.10476376897714323, 'booster': 'gblinear', 'gamma': 0.29325019863754526, 'reg_alpha': 0.715012004582257, 'reg_lambda': 0.493250821492887}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:41,226] Trial 55 finished with value: 0.0 and parameters: {'n_estimators': 245, 'max_depth': 8, 'max_leaves': 7, 'learning_rate': 0.02293126744615284, 'booster': 'gbtree', 'gamma': 0.8302075869048477, 'reg_alpha': 0.1419833007628663, 'reg_lambda': 0.6069046515098359}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:48,545] Trial 56 finished with value: 0.0 and parameters: {'n_estimators': 597, 'max_depth': 4, 'max_leaves': 6, 'learning_rate': 0.1293419278632974, 'booster': 'dart', 'gamma': 0.6983361530312183, 'reg_alpha': 0.5203652340027488, 'reg_lambda': 0.2659905057903414}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:52:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:52:48,629] Trial 57 finished with value: 0.0 and parameters: {'n_estimators': 647, 'max_depth': 5, 'max_leaves': 5, 'learning_rate': 0.18068502729394242, 'booster': 'gblinear', 'gamma': 0.6398176740360701, 'reg_alpha': 0.7596998591223455, 'reg_lambda': 0.9018212485541537}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:48,708] Trial 58 finished with value: 0.0 and parameters: {'n_estimators': 339, 'max_depth': 7, 'max_leaves': 7, 'learning_rate': 0.09411148235697783, 'booster': 'gbtree', 'gamma': 0.5901997541723077, 'reg_alpha': 0.5696643561067556, 'reg_lambda': 0.37974472193284625}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:52:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:52:48,793] Trial 59 finished with value: 0.0 and parameters: {'n_estimators': 516, 'max_depth': 6, 'max_leaves': 4, 'learning_rate': 0.14970719951805206, 'booster': 'gblinear', 'gamma': 0.1142193518561088, 'reg_alpha': 0.25084990993627865, 'reg_lambda': 0.43571915754180357}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:48,921] Trial 60 finished with value: 0.0 and parameters: {'n_estimators': 961, 'max_depth': 3, 'max_leaves': 3, 'learning_rate': 0.05237971160952483, 'booster': 'gbtree', 'gamma': 0.3234888719700489, 'reg_alpha': 0.631670737952746, 'reg_lambda': 0.700152333207249}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:49,026] Trial 61 finished with value: 0.0 and parameters: {'n_estimators': 827, 'max_depth': 6, 'max_leaves': 10, 'learning_rate': 0.11520729528096765, 'booster': 'gbtree', 'gamma': 0.7269466663977266, 'reg_alpha': 0.6956284538170974, 'reg_lambda': 0.33963628658924283}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:49,074] Trial 62 finished with value: 0.0 and parameters: {'n_estimators': 181, 'max_depth': 6, 'max_leaves': 8, 'learning_rate': 0.16363359530055177, 'booster': 'gbtree', 'gamma': 0.9543350387097198, 'reg_alpha': 0.9589822867973063, 'reg_lambda': 0.5566150109658987}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:49,192] Trial 63 finished with value: 0.0 and parameters: {'n_estimators': 887, 'max_depth': 5, 'max_leaves': 10, 'learning_rate': 0.03963086946091323, 'booster': 'gbtree', 'gamma': 0.5297110927781017, 'reg_alpha': 0.8223539038493226, 'reg_lambda': 0.42066458847750626}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:49,295] Trial 64 finished with value: 0.0 and parameters: {'n_estimators': 569, 'max_depth': 7, 'max_leaves': 9, 'learning_rate': 0.018306598619564123, 'booster': 'gbtree', 'gamma': 0.5968494856159814, 'reg_alpha': 0.7292344140085196, 'reg_lambda': 0.2330046150236283}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:49,337] Trial 65 finished with value: 0.0 and parameters: {'n_estimators': 133, 'max_depth': 4, 'max_leaves': 10, 'learning_rate': 0.13527596498600783, 'booster': 'gbtree', 'gamma': 0.3879469901780883, 'reg_alpha': 0.7924481484759703, 'reg_lambda': 0.5029363800292561}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:49,433] Trial 66 finished with value: 0.0 and parameters: {'n_estimators': 760, 'max_depth': 9, 'max_leaves': 9, 'learning_rate': 0.06849566461300947, 'booster': 'gbtree', 'gamma': 0.6578278446497465, 'reg_alpha': 0.8689883756664195, 'reg_lambda': 0.5966861232241831}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:52,594] Trial 67 finished with value: 0.0 and parameters: {'n_estimators': 381, 'max_depth': 8, 'max_leaves': 8, 'learning_rate': 0.1491488940605206, 'booster': 'dart', 'gamma': 0.5538452287054911, 'reg_alpha': 0.2035719328832203, 'reg_lambda': 0.2949659423979105}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:52:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:52:52,647] Trial 68 finished with value: 0.0 and parameters: {'n_estimators': 425, 'max_depth': 7, 'max_leaves': 10, 'learning_rate': 0.1234574271453005, 'booster': 'gblinear', 'gamma': 0.765517841190893, 'reg_alpha': 0.13285242045038892, 'reg_lambda': 0.4614361659593668}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:52,741] Trial 69 finished with value: 0.0 and parameters: {'n_estimators': 679, 'max_depth': 5, 'max_leaves': 7, 'learning_rate': 0.10949636148299344, 'booster': 'gbtree', 'gamma': 0.4353551216554363, 'reg_alpha': 0.6274139032863775, 'reg_lambda': 0.32954890772527234}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:52:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:52:52,912] Trial 70 finished with value: 0.0 and parameters: {'n_estimators': 731, 'max_depth': 6, 'max_leaves': 6, 'learning_rate': 0.09646241513166431, 'booster': 'gblinear', 'gamma': 0.7174639974730277, 'reg_alpha': 0.6545785490357426, 'reg_lambda': 0.8326375593008377}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:52,971] Trial 71 finished with value: 0.0 and parameters: {'n_estimators': 196, 'max_depth': 8, 'max_leaves': 5, 'learning_rate': 0.1743202620711116, 'booster': 'gbtree', 'gamma': 0.46679992562832884, 'reg_alpha': 0.9053952774396081, 'reg_lambda': 0.4973531166493632}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:53,045] Trial 72 finished with value: 0.0 and parameters: {'n_estimators': 235, 'max_depth': 10, 'max_leaves': 9, 'learning_rate': 0.134254288399362, 'booster': 'gbtree', 'gamma': 0.4993768864054841, 'reg_alpha': 0.7746643771359667, 'reg_lambda': 0.4143108027001009}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:53,120] Trial 73 finished with value: 0.0 and parameters: {'n_estimators': 278, 'max_depth': 8, 'max_leaves': 7, 'learning_rate': 0.2088769146472728, 'booster': 'gbtree', 'gamma': 0.23371564403596495, 'reg_alpha': 0.8418763270519319, 'reg_lambda': 0.5820327528540645}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:53,166] Trial 74 finished with value: 0.0 and parameters: {'n_estimators': 135, 'max_depth': 8, 'max_leaves': 4, 'learning_rate': 0.08071702870832548, 'booster': 'gbtree', 'gamma': 0.5366597963728845, 'reg_alpha': 0.9637451711162155, 'reg_lambda': 0.36197266343290935}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:53,214] Trial 75 finished with value: 0.0 and parameters: {'n_estimators': 146, 'max_depth': 7, 'max_leaves': 6, 'learning_rate': 0.15109583492460085, 'booster': 'gbtree', 'gamma': 0.6168145770362483, 'reg_alpha': 0.688908836481079, 'reg_lambda': 0.5355379833285235}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:52:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:52:53,342] Trial 76 finished with value: 0.0 and parameters: {'n_estimators': 328, 'max_depth': 9, 'max_leaves': 10, 'learning_rate': 0.12359741264547924, 'booster': 'gblinear', 'gamma': 0.5703517635754878, 'reg_alpha': 0.5904747997288923, 'reg_lambda': 0.6268863507623947}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:53,404] Trial 77 finished with value: 0.0 and parameters: {'n_estimators': 300, 'max_depth': 4, 'max_leaves': 8, 'learning_rate': 0.14429547955795455, 'booster': 'gbtree', 'gamma': 0.6804080305988995, 'reg_alpha': 0.3143655335167995, 'reg_lambda': 0.9962448339362602}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:52:53,461] Trial 78 finished with value: 0.0 and parameters: {'n_estimators': 261, 'max_depth': 6, 'max_leaves': 5, 'learning_rate': 0.15825720718872127, 'booster': 'gbtree', 'gamma': 0.6457716154426704, 'reg_alpha': 0.7306887923549351, 'reg_lambda': 0.77534897633632}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:52:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:52:53,490] Trial 79 finished with value: 0.0 and parameters: {'n_estimators': 100, 'max_depth': 8, 'max_leaves': 9, 'learning_rate': 0.17074298567727095, 'booster': 'gblinear', 'gamma': 0.15369701952878756, 'reg_alpha': 0.8433246886286001, 'reg_lambda': 0.3871779701247555}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:53:15,625] Trial 80 finished with value: 0.0 and parameters: {'n_estimators': 946, 'max_depth': 7, 'max_leaves': 10, 'learning_rate': 0.25512982522250116, 'booster': 'dart', 'gamma': 0.2699826082363, 'reg_alpha': 0.8091388979744556, 'reg_lambda': 0.27353302704177235}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:53:15,762] Trial 81 finished with value: 0.0 and parameters: {'n_estimators': 897, 'max_depth': 9, 'max_leaves': 5, 'learning_rate': 0.23300026219258266, 'booster': 'gbtree', 'gamma': 0.44206905146324776, 'reg_alpha': 0.45260413890588924, 'reg_lambda': 0.9178018106069452}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:53:15,900] Trial 82 finished with value: 0.0 and parameters: {'n_estimators': 955, 'max_depth': 9, 'max_leaves': 6, 'learning_rate': 0.1948594177629065, 'booster': 'gbtree', 'gamma': 0.3746599434601747, 'reg_alpha': 0.1636504926902062, 'reg_lambda': 0.8726025463810075}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:53:16,047] Trial 83 finished with value: 0.0 and parameters: {'n_estimators': 995, 'max_depth': 5, 'max_leaves': 4, 'learning_rate': 0.209713741145601, 'booster': 'gbtree', 'gamma': 0.48891842665641333, 'reg_alpha': 0.2508392122308064, 'reg_lambda': 0.7881441218174096}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:53:16,208] Trial 84 finished with value: 0.0 and parameters: {'n_estimators': 873, 'max_depth': 10, 'max_leaves': 5, 'learning_rate': 0.18920442530244602, 'booster': 'gbtree', 'gamma': 0.20491529423008747, 'reg_alpha': 0.2127206824715302, 'reg_lambda': 0.3252314571807604}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:53:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:53:16,318] Trial 85 finished with value: 0.0 and parameters: {'n_estimators': 932, 'max_depth': 8, 'max_leaves': 3, 'learning_rate': 0.11751007652682832, 'booster': 'gblinear', 'gamma': 0.6021687119689013, 'reg_alpha': 0.3652287853850823, 'reg_lambda': 0.20387070553333694}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:53:16,399] Trial 86 finished with value: 0.0 and parameters: {'n_estimators': 461, 'max_depth': 3, 'max_leaves': 5, 'learning_rate': 0.2776790996334262, 'booster': 'gbtree', 'gamma': 0.5068382560640761, 'reg_alpha': 0.31583335035283816, 'reg_lambda': 0.7157574472231184}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:53:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:53:16,452] Trial 87 finished with value: 0.0 and parameters: {'n_estimators': 361, 'max_depth': 6, 'max_leaves': 7, 'learning_rate': 0.21615992860810262, 'booster': 'gblinear', 'gamma': 0.3397174687866743, 'reg_alpha': 0.7119688985602555, 'reg_lambda': 0.4738113314548511}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:53:16,531] Trial 88 finished with value: 0.0 and parameters: {'n_estimators': 519, 'max_depth': 9, 'max_leaves': 6, 'learning_rate': 0.24438247556889633, 'booster': 'gbtree', 'gamma': 0.4620349402891632, 'reg_alpha': 0.567589988948147, 'reg_lambda': 0.31028776805641267}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:53:16,641] Trial 89 finished with value: 0.0 and parameters: {'n_estimators': 636, 'max_depth': 5, 'max_leaves': 4, 'learning_rate': 0.13816576915502216, 'booster': 'gbtree', 'gamma': 0.41642968729767355, 'reg_alpha': 0.7447851006041525, 'reg_lambda': 0.24239117236124536}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:53:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:53:16,724] Trial 90 finished with value: 0.0 and parameters: {'n_estimators': 832, 'max_depth': 7, 'max_leaves': 7, 'learning_rate': 0.031750072725227826, 'booster': 'gblinear', 'gamma': 0.5502330234025001, 'reg_alpha': 0.15492834377440484, 'reg_lambda': 0.8817501897634574}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:53:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:53:16,835] Trial 91 finished with value: 0.0 and parameters: {'n_estimators': 178, 'max_depth': 9, 'max_leaves': 10, 'learning_rate': 0.2237285682861626, 'booster': 'gblinear', 'gamma': 0.6810114011686814, 'reg_alpha': 0.2751882243843534, 'reg_lambda': 0.4486842985915786}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:53:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:53:16,908] Trial 92 finished with value: 0.0 and parameters: {'n_estimators': 230, 'max_depth': 10, 'max_leaves': 10, 'learning_rate': 0.2004637031235013, 'booster': 'gblinear', 'gamma': 0.5176343437753906, 'reg_alpha': 0.26895343658511334, 'reg_lambda': 0.4348497075277925}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:53:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:53:16,962] Trial 93 finished with value: 0.0 and parameters: {'n_estimators': 198, 'max_depth': 9, 'max_leaves': 10, 'learning_rate': 0.10937704207667914, 'booster': 'gblinear', 'gamma': 0.5681010539463451, 'reg_alpha': 0.19867719187721902, 'reg_lambda': 0.35301339505044615}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:53:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:53:16,997] Trial 94 finished with value: 0.0 and parameters: {'n_estimators': 158, 'max_depth': 8, 'max_leaves': 9, 'learning_rate': 0.16714555446425053, 'booster': 'gblinear', 'gamma': 0.5419682641896674, 'reg_alpha': 0.1800382033830703, 'reg_lambda': 0.3971681425714622}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:53:32,138] Trial 95 finished with value: 0.0 and parameters: {'n_estimators': 779, 'max_depth': 6, 'max_leaves': 10, 'learning_rate': 0.1787851130153107, 'booster': 'dart', 'gamma': 0.6364897990273494, 'reg_alpha': 0.347070052521683, 'reg_lambda': 0.5236683377435927}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:53:32,292] Trial 96 finished with value: 0.0 and parameters: {'n_estimators': 971, 'max_depth': 4, 'max_leaves': 9, 'learning_rate': 0.13030590037034728, 'booster': 'gbtree', 'gamma': 0.6131284250304174, 'reg_alpha': 0.29646084236955816, 'reg_lambda': 0.4144200811009629}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:53:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:53:32,405] Trial 97 finished with value: 0.0 and parameters: {'n_estimators': 931, 'max_depth': 9, 'max_leaves': 6, 'learning_rate': 0.012462239412077615, 'booster': 'gblinear', 'gamma': 0.5745610242849879, 'reg_alpha': 0.4076989131069819, 'reg_lambda': 0.9448832547206678}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-03-06 19:53:32,467] Trial 98 finished with value: 0.0 and parameters: {'n_estimators': 257, 'max_depth': 8, 'max_leaves': 8, 'learning_rate': 0.23332727934844635, 'booster': 'gbtree', 'gamma': 0.5219001034045816, 'reg_alpha': 0.6486615112893223, 'reg_lambda': 0.28175242921467086}. Best is trial 0 with value: 0.0.\n",
      "/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [19:53:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"max_depth\", \"max_leaves\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-06 19:53:32,519] Trial 99 finished with value: 0.0 and parameters: {'n_estimators': 128, 'max_depth': 7, 'max_leaves': 5, 'learning_rate': 0.051149027585056, 'booster': 'gblinear', 'gamma': 0.4870458337568237, 'reg_alpha': 0.23257350337773244, 'reg_lambda': 0.49015609217329487}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n",
      "Best hyperparameters: {'n_estimators': 126, 'max_depth': 8, 'max_leaves': 7, 'learning_rate': 0.23811969682644046, 'booster': 'gbtree', 'gamma': 0.5858818769373417, 'reg_alpha': 0.2303850918748473, 'reg_lambda': 0.8482876059976411}\n",
      "Execution time: 1.802035884062449 minutes\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'n_estimators': 126,\n 'max_depth': 8,\n 'max_leaves': 7,\n 'learning_rate': 0.23811969682644046,\n 'booster': 'gbtree',\n 'gamma': 0.5858818769373417,\n 'reg_alpha': 0.2303850918748473,\n 'reg_lambda': 0.8482876059976411}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBOptimizer(x_train, y_train, x_test, y_test).xgb_optuna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T01:53:32.652985Z",
     "start_time": "2024-03-07T01:53:32.534231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93        72\n",
      "           1       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.87        79\n",
      "   macro avg       0.45      0.48      0.47        79\n",
      "weighted avg       0.83      0.87      0.85        79\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Define the hyperparameters\n",
    "hyperparameters = {\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': 4,\n",
    "    'max_leaves': 8,\n",
    "    'learning_rate': 0.19907630294635822,\n",
    "    'booster': 'gbtree',\n",
    "    'gamma': 0.23192419129293812,\n",
    "    'reg_alpha': 0.29521621673453086,\n",
    "    'reg_lambda': 0.5262324218052595\n",
    "}\n",
    "\n",
    "# Create the XGBoost model\n",
    "model = xgb.XGBClassifier(**hyperparameters)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "{0, 1}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T03:06:44.147219Z",
     "start_time": "2024-03-07T03:06:44.136028Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
