{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-07T01:45:08.372375Z",
     "start_time": "2024-03-07T01:45:08.369415Z"
    }
   },
   "outputs": [],
   "source": [
    "from machine_learning.xgb_def import XGBOptimizer\n",
    "import pandas as pd\n",
    "from opt_funct.data_fuct import functions\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "      Timestamp  Gmtoffset             Datetime        Open        High  \\\n0    1602509400          0  2020-10-12 13:30:00  120.059997  121.330101   \n1    1602513000          0  2020-10-12 14:30:00  120.919998  122.639999   \n2    1602516600          0  2020-10-12 15:30:00  122.525001  123.629997   \n3    1602520200          0  2020-10-12 16:30:00  123.260002  124.000000   \n4    1602523800          0  2020-10-12 17:30:00  124.089996  125.180000   \n..          ...        ...                  ...         ...         ...   \n390  1609432200          0  2020-12-31 16:30:00  132.529998  132.800003   \n391  1609435800          0  2020-12-31 17:30:00  132.619995  132.717605   \n392  1609439400          0  2020-12-31 18:30:00  132.565002  132.889999   \n393  1609443000          0  2020-12-31 19:30:00  132.770004  133.179992   \n394  1609446600          0  2020-12-31 20:30:00  132.794998  133.330001   \n\n            Low       Close      Volume       X_t-1       X_t-2       X_t-3  \\\n0    119.284500  120.919998  48082766.0         NaN         NaN         NaN   \n1    120.769996  122.529998  27028067.0  120.919998         NaN         NaN   \n2    122.290000  123.261001  35722193.0  122.529998  120.919998         NaN   \n3    123.040000  123.930000  22891159.0  123.261001  122.529998  120.919998   \n4    123.910003  125.050003  31443470.0  123.930000  123.261001  122.529998   \n..          ...         ...         ...         ...         ...         ...   \n390  131.720001  132.619995  13538948.0  132.529998  132.884994  133.679992   \n391  132.310104  132.560806   7474176.0  132.619995  132.529998  132.884994   \n392  132.009994  132.764999   9408857.0  132.560806  132.619995  132.529998   \n393  132.565994  132.800003  10147999.0  132.764999  132.560806  132.619995   \n394  132.449996  132.580001  11777361.0  132.800003  132.764999  132.560806   \n\n           Pt_5        RSI  Y_BUY  Y_SELL  \n0    124.314102        NaN      1       0  \n1    124.419998        NaN      0       0  \n2    123.757202        NaN      0       0  \n3    124.430000        NaN      0       0  \n4    123.080001        NaN      0       0  \n..          ...        ...    ...     ...  \n390         NaN  50.983206      0       0  \n391         NaN  50.783652      0       0  \n392         NaN  51.463321      0       0  \n393         NaN  51.582189      0       0  \n394         NaN  50.771752      0       0  \n\n[395 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Timestamp</th>\n      <th>Gmtoffset</th>\n      <th>Datetime</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Volume</th>\n      <th>X_t-1</th>\n      <th>X_t-2</th>\n      <th>X_t-3</th>\n      <th>Pt_5</th>\n      <th>RSI</th>\n      <th>Y_BUY</th>\n      <th>Y_SELL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1602509400</td>\n      <td>0</td>\n      <td>2020-10-12 13:30:00</td>\n      <td>120.059997</td>\n      <td>121.330101</td>\n      <td>119.284500</td>\n      <td>120.919998</td>\n      <td>48082766.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>124.314102</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1602513000</td>\n      <td>0</td>\n      <td>2020-10-12 14:30:00</td>\n      <td>120.919998</td>\n      <td>122.639999</td>\n      <td>120.769996</td>\n      <td>122.529998</td>\n      <td>27028067.0</td>\n      <td>120.919998</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>124.419998</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1602516600</td>\n      <td>0</td>\n      <td>2020-10-12 15:30:00</td>\n      <td>122.525001</td>\n      <td>123.629997</td>\n      <td>122.290000</td>\n      <td>123.261001</td>\n      <td>35722193.0</td>\n      <td>122.529998</td>\n      <td>120.919998</td>\n      <td>NaN</td>\n      <td>123.757202</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1602520200</td>\n      <td>0</td>\n      <td>2020-10-12 16:30:00</td>\n      <td>123.260002</td>\n      <td>124.000000</td>\n      <td>123.040000</td>\n      <td>123.930000</td>\n      <td>22891159.0</td>\n      <td>123.261001</td>\n      <td>122.529998</td>\n      <td>120.919998</td>\n      <td>124.430000</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1602523800</td>\n      <td>0</td>\n      <td>2020-10-12 17:30:00</td>\n      <td>124.089996</td>\n      <td>125.180000</td>\n      <td>123.910003</td>\n      <td>125.050003</td>\n      <td>31443470.0</td>\n      <td>123.930000</td>\n      <td>123.261001</td>\n      <td>122.529998</td>\n      <td>123.080001</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>390</th>\n      <td>1609432200</td>\n      <td>0</td>\n      <td>2020-12-31 16:30:00</td>\n      <td>132.529998</td>\n      <td>132.800003</td>\n      <td>131.720001</td>\n      <td>132.619995</td>\n      <td>13538948.0</td>\n      <td>132.529998</td>\n      <td>132.884994</td>\n      <td>133.679992</td>\n      <td>NaN</td>\n      <td>50.983206</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>391</th>\n      <td>1609435800</td>\n      <td>0</td>\n      <td>2020-12-31 17:30:00</td>\n      <td>132.619995</td>\n      <td>132.717605</td>\n      <td>132.310104</td>\n      <td>132.560806</td>\n      <td>7474176.0</td>\n      <td>132.619995</td>\n      <td>132.529998</td>\n      <td>132.884994</td>\n      <td>NaN</td>\n      <td>50.783652</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>392</th>\n      <td>1609439400</td>\n      <td>0</td>\n      <td>2020-12-31 18:30:00</td>\n      <td>132.565002</td>\n      <td>132.889999</td>\n      <td>132.009994</td>\n      <td>132.764999</td>\n      <td>9408857.0</td>\n      <td>132.560806</td>\n      <td>132.619995</td>\n      <td>132.529998</td>\n      <td>NaN</td>\n      <td>51.463321</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>393</th>\n      <td>1609443000</td>\n      <td>0</td>\n      <td>2020-12-31 19:30:00</td>\n      <td>132.770004</td>\n      <td>133.179992</td>\n      <td>132.565994</td>\n      <td>132.800003</td>\n      <td>10147999.0</td>\n      <td>132.764999</td>\n      <td>132.560806</td>\n      <td>132.619995</td>\n      <td>NaN</td>\n      <td>51.582189</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>394</th>\n      <td>1609446600</td>\n      <td>0</td>\n      <td>2020-12-31 20:30:00</td>\n      <td>132.794998</td>\n      <td>133.330001</td>\n      <td>132.449996</td>\n      <td>132.580001</td>\n      <td>11777361.0</td>\n      <td>132.800003</td>\n      <td>132.764999</td>\n      <td>132.560806</td>\n      <td>NaN</td>\n      <td>50.771752</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>395 rows Ã— 15 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = functions.clean_ds(pd.read_csv('./data/aapl_1h_train.csv'))\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T01:41:51.759466Z",
     "start_time": "2024-03-07T01:41:51.713361Z"
    }
   },
   "id": "570e764aa7a0ecce"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-06 19:45:12,509] A new study created in memory with name: no-name-83ac3e10-c3f2-4eca-a738-9e15ec9cdd96\n",
      "/Users/rixon/Desktop/ITESO/11/Trading/Proyecto3/003_ML/machine_learning/xgb_def.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "/Users/rixon/Desktop/ITESO/11/Trading/Proyecto3/003_ML/machine_learning/xgb_def.py:21: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'gamma': trial.suggest_loguniform('gamma', 0.1, 1),\n",
      "/Users/rixon/Desktop/ITESO/11/Trading/Proyecto3/003_ML/machine_learning/xgb_def.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.1, 1),\n",
      "/Users/rixon/Desktop/ITESO/11/Trading/Proyecto3/003_ML/machine_learning/xgb_def.py:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 0.1, 1),\n",
      "[W 2024-03-06 19:45:12,636] Trial 0 failed with parameters: {'n_estimators': 315, 'max_depth': 5, 'max_leaves': 5, 'learning_rate': 0.03197869772372708, 'booster': 'dart', 'gamma': 0.10393563309634389, 'reg_alpha': 0.18446522726263795, 'reg_lambda': 0.7520878439524186} because of the following error: XGBoostError('[19:45:12] /Users/runner/work/xgboost/xgboost/src/metric/metric.cc:49: Unknown metric function binary:logistic\\nStack trace:\\n  [bt] (0) 1   libxgboost.dylib                    0x00000001697f0994 dmlc::LogMessageFatal::~LogMessageFatal() + 124\\n  [bt] (1) 2   libxgboost.dylib                    0x00000001699705c4 xgboost::Metric::Create(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, xgboost::Context const*) + 124\\n  [bt] (2) 3   libxgboost.dylib                    0x00000001699461d8 xgboost::LearnerConfiguration::ConfigureMetrics(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 216\\n  [bt] (3) 4   libxgboost.dylib                    0x00000001699381c8 xgboost::LearnerConfiguration::Configure() + 1072\\n  [bt] (4) 5   libxgboost.dylib                    0x00000001699384b0 xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 128\\n  [bt] (5) 6   libxgboost.dylib                    0x0000000169810ea4 XGBoosterUpdateOneIter + 144\\n  [bt] (6) 7   libffi.8.dylib                      0x000000010337004c ffi_call_SYSV + 76\\n  [bt] (7) 8   libffi.8.dylib                      0x000000010336d834 ffi_call_int + 1404\\n  [bt] (8) 9   _ctypes.cpython-311-darwin.so       0x00000001030a8150 _ctypes_callproc + 752\\n\\n').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rixon/anaconda3/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/Users/rixon/Desktop/ITESO/11/Trading/Proyecto3/003_ML/machine_learning/xgb_def.py\", line 37, in <lambda>\n",
      "    study.optimize(lambda trial: self.opt_xgb(trial), n_trials=100)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rixon/Desktop/ITESO/11/Trading/Proyecto3/003_ML/machine_learning/xgb_def.py\", line 29, in opt_xgb\n",
      "    model.fit(self.x_train, self.y_train)\n",
      "  File \"/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1519, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/Users/rixon/anaconda3/lib/python3.11/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [19:45:12] /Users/runner/work/xgboost/xgboost/src/metric/metric.cc:49: Unknown metric function binary:logistic\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x00000001697f0994 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x00000001699705c4 xgboost::Metric::Create(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, xgboost::Context const*) + 124\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001699461d8 xgboost::LearnerConfiguration::ConfigureMetrics(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 216\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001699381c8 xgboost::LearnerConfiguration::Configure() + 1072\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x00000001699384b0 xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 128\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x0000000169810ea4 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (6) 7   libffi.8.dylib                      0x000000010337004c ffi_call_SYSV + 76\n",
      "  [bt] (7) 8   libffi.8.dylib                      0x000000010336d834 ffi_call_int + 1404\n",
      "  [bt] (8) 9   _ctypes.cpython-311-darwin.so       0x00000001030a8150 _ctypes_callproc + 752\n",
      "\n",
      "\n",
      "[W 2024-03-06 19:45:12,640] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[19:45:12] /Users/runner/work/xgboost/xgboost/src/metric/metric.cc:49: Unknown metric function binary:logistic\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x00000001697f0994 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n  [bt] (1) 2   libxgboost.dylib                    0x00000001699705c4 xgboost::Metric::Create(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, xgboost::Context const*) + 124\n  [bt] (2) 3   libxgboost.dylib                    0x00000001699461d8 xgboost::LearnerConfiguration::ConfigureMetrics(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 216\n  [bt] (3) 4   libxgboost.dylib                    0x00000001699381c8 xgboost::LearnerConfiguration::Configure() + 1072\n  [bt] (4) 5   libxgboost.dylib                    0x00000001699384b0 xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 128\n  [bt] (5) 6   libxgboost.dylib                    0x0000000169810ea4 XGBoosterUpdateOneIter + 144\n  [bt] (6) 7   libffi.8.dylib                      0x000000010337004c ffi_call_SYSV + 76\n  [bt] (7) 8   libffi.8.dylib                      0x000000010336d834 ffi_call_int + 1404\n  [bt] (8) 9   _ctypes.cpython-311-darwin.so       0x00000001030a8150 _ctypes_callproc + 752\n\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mXGBoostError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m y \u001B[38;5;241m=\u001B[39m close_data[[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mY_BUY\u001B[39m\u001B[38;5;124m'\u001B[39m]]\n\u001B[1;32m      4\u001B[0m x_train, x_test, y_train, y_test \u001B[38;5;241m=\u001B[39m train_test_split(x, y, test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[0;32m----> 5\u001B[0m XGBOptimizer(x_train, y_train, x_test, y_test)\u001B[38;5;241m.\u001B[39mxgb_optuna()\n",
      "File \u001B[0;32m~/Desktop/ITESO/11/Trading/Proyecto3/003_ML/machine_learning/xgb_def.py:37\u001B[0m, in \u001B[0;36mXGBOptimizer.xgb_optuna\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     35\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m     36\u001B[0m study \u001B[38;5;241m=\u001B[39m optuna\u001B[38;5;241m.\u001B[39mcreate_study(direction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmaximize\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 37\u001B[0m study\u001B[38;5;241m.\u001B[39moptimize(\u001B[38;5;28;01mlambda\u001B[39;00m trial: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopt_xgb(trial), n_trials\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m)\n\u001B[1;32m     38\u001B[0m trial \u001B[38;5;241m=\u001B[39m study\u001B[38;5;241m.\u001B[39mbest_trial\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAccuracy: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(trial\u001B[38;5;241m.\u001B[39mvalue))\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/optuna/study/study.py:451\u001B[0m, in \u001B[0;36mStudy.optimize\u001B[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[1;32m    348\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21moptimize\u001B[39m(\n\u001B[1;32m    349\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    350\u001B[0m     func: ObjectiveFuncType,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    357\u001B[0m     show_progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    358\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    359\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Optimize an objective function.\u001B[39;00m\n\u001B[1;32m    360\u001B[0m \n\u001B[1;32m    361\u001B[0m \u001B[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    449\u001B[0m \u001B[38;5;124;03m            If nested invocation of this method occurs.\u001B[39;00m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 451\u001B[0m     _optimize(\n\u001B[1;32m    452\u001B[0m         study\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    453\u001B[0m         func\u001B[38;5;241m=\u001B[39mfunc,\n\u001B[1;32m    454\u001B[0m         n_trials\u001B[38;5;241m=\u001B[39mn_trials,\n\u001B[1;32m    455\u001B[0m         timeout\u001B[38;5;241m=\u001B[39mtimeout,\n\u001B[1;32m    456\u001B[0m         n_jobs\u001B[38;5;241m=\u001B[39mn_jobs,\n\u001B[1;32m    457\u001B[0m         catch\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mtuple\u001B[39m(catch) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(catch, Iterable) \u001B[38;5;28;01melse\u001B[39;00m (catch,),\n\u001B[1;32m    458\u001B[0m         callbacks\u001B[38;5;241m=\u001B[39mcallbacks,\n\u001B[1;32m    459\u001B[0m         gc_after_trial\u001B[38;5;241m=\u001B[39mgc_after_trial,\n\u001B[1;32m    460\u001B[0m         show_progress_bar\u001B[38;5;241m=\u001B[39mshow_progress_bar,\n\u001B[1;32m    461\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/optuna/study/_optimize.py:66\u001B[0m, in \u001B[0;36m_optimize\u001B[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m---> 66\u001B[0m         _optimize_sequential(\n\u001B[1;32m     67\u001B[0m             study,\n\u001B[1;32m     68\u001B[0m             func,\n\u001B[1;32m     69\u001B[0m             n_trials,\n\u001B[1;32m     70\u001B[0m             timeout,\n\u001B[1;32m     71\u001B[0m             catch,\n\u001B[1;32m     72\u001B[0m             callbacks,\n\u001B[1;32m     73\u001B[0m             gc_after_trial,\n\u001B[1;32m     74\u001B[0m             reseed_sampler_rng\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m     75\u001B[0m             time_start\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     76\u001B[0m             progress_bar\u001B[38;5;241m=\u001B[39mprogress_bar,\n\u001B[1;32m     77\u001B[0m         )\n\u001B[1;32m     78\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     79\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/optuna/study/_optimize.py:163\u001B[0m, in \u001B[0;36m_optimize_sequential\u001B[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[0m\n\u001B[1;32m    160\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m    162\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 163\u001B[0m     frozen_trial \u001B[38;5;241m=\u001B[39m _run_trial(study, func, catch)\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    165\u001B[0m     \u001B[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001B[39;00m\n\u001B[1;32m    166\u001B[0m     \u001B[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001B[39;00m\n\u001B[1;32m    167\u001B[0m     \u001B[38;5;66;03m# Please refer to the following PR for further details:\u001B[39;00m\n\u001B[1;32m    168\u001B[0m     \u001B[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001B[39;00m\n\u001B[1;32m    169\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m gc_after_trial:\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/optuna/study/_optimize.py:251\u001B[0m, in \u001B[0;36m_run_trial\u001B[0;34m(study, func, catch)\u001B[0m\n\u001B[1;32m    244\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShould not reach.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    246\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    247\u001B[0m     frozen_trial\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m==\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mFAIL\n\u001B[1;32m    248\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m func_err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    249\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func_err, catch)\n\u001B[1;32m    250\u001B[0m ):\n\u001B[0;32m--> 251\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m func_err\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m frozen_trial\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/optuna/study/_optimize.py:200\u001B[0m, in \u001B[0;36m_run_trial\u001B[0;34m(study, func, catch)\u001B[0m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m get_heartbeat_thread(trial\u001B[38;5;241m.\u001B[39m_trial_id, study\u001B[38;5;241m.\u001B[39m_storage):\n\u001B[1;32m    199\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 200\u001B[0m         value_or_values \u001B[38;5;241m=\u001B[39m func(trial)\n\u001B[1;32m    201\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mTrialPruned \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    202\u001B[0m         \u001B[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001B[39;00m\n\u001B[1;32m    203\u001B[0m         state \u001B[38;5;241m=\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mPRUNED\n",
      "File \u001B[0;32m~/Desktop/ITESO/11/Trading/Proyecto3/003_ML/machine_learning/xgb_def.py:37\u001B[0m, in \u001B[0;36mXGBOptimizer.xgb_optuna.<locals>.<lambda>\u001B[0;34m(trial)\u001B[0m\n\u001B[1;32m     35\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m     36\u001B[0m study \u001B[38;5;241m=\u001B[39m optuna\u001B[38;5;241m.\u001B[39mcreate_study(direction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmaximize\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 37\u001B[0m study\u001B[38;5;241m.\u001B[39moptimize(\u001B[38;5;28;01mlambda\u001B[39;00m trial: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopt_xgb(trial), n_trials\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m)\n\u001B[1;32m     38\u001B[0m trial \u001B[38;5;241m=\u001B[39m study\u001B[38;5;241m.\u001B[39mbest_trial\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAccuracy: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(trial\u001B[38;5;241m.\u001B[39mvalue))\n",
      "File \u001B[0;32m~/Desktop/ITESO/11/Trading/Proyecto3/003_ML/machine_learning/xgb_def.py:29\u001B[0m, in \u001B[0;36mXGBOptimizer.opt_xgb\u001B[0;34m(self, trial)\u001B[0m\n\u001B[1;32m     15\u001B[0m params \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn_estimators\u001B[39m\u001B[38;5;124m'\u001B[39m: trial\u001B[38;5;241m.\u001B[39msuggest_int(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn_estimators\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m1000\u001B[39m),\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_depth\u001B[39m\u001B[38;5;124m'\u001B[39m: trial\u001B[38;5;241m.\u001B[39msuggest_int(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_depth\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m10\u001B[39m),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;66;03m# 'device': 'cuda' # Si no tienen GPU y linux comentar esta linea\u001B[39;00m\n\u001B[1;32m     27\u001B[0m }\n\u001B[1;32m     28\u001B[0m model \u001B[38;5;241m=\u001B[39m xgb\u001B[38;5;241m.\u001B[39mXGBClassifier(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams)\n\u001B[0;32m---> 29\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx_train, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39my_train)\n\u001B[1;32m     30\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx_test)\n\u001B[1;32m     31\u001B[0m f1 \u001B[38;5;241m=\u001B[39m f1_score(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39my_test, y_pred)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/xgboost/core.py:730\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    728\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[1;32m    729\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[0;32m--> 730\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/xgboost/sklearn.py:1519\u001B[0m, in \u001B[0;36mXGBClassifier.fit\u001B[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001B[0m\n\u001B[1;32m   1491\u001B[0m (\n\u001B[1;32m   1492\u001B[0m     model,\n\u001B[1;32m   1493\u001B[0m     metric,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1498\u001B[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001B[1;32m   1499\u001B[0m )\n\u001B[1;32m   1500\u001B[0m train_dmatrix, evals \u001B[38;5;241m=\u001B[39m _wrap_evaluation_matrices(\n\u001B[1;32m   1501\u001B[0m     missing\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmissing,\n\u001B[1;32m   1502\u001B[0m     X\u001B[38;5;241m=\u001B[39mX,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     feature_types\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_types,\n\u001B[1;32m   1517\u001B[0m )\n\u001B[0;32m-> 1519\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_Booster \u001B[38;5;241m=\u001B[39m train(\n\u001B[1;32m   1520\u001B[0m     params,\n\u001B[1;32m   1521\u001B[0m     train_dmatrix,\n\u001B[1;32m   1522\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_num_boosting_rounds(),\n\u001B[1;32m   1523\u001B[0m     evals\u001B[38;5;241m=\u001B[39mevals,\n\u001B[1;32m   1524\u001B[0m     early_stopping_rounds\u001B[38;5;241m=\u001B[39mearly_stopping_rounds,\n\u001B[1;32m   1525\u001B[0m     evals_result\u001B[38;5;241m=\u001B[39mevals_result,\n\u001B[1;32m   1526\u001B[0m     obj\u001B[38;5;241m=\u001B[39mobj,\n\u001B[1;32m   1527\u001B[0m     custom_metric\u001B[38;5;241m=\u001B[39mmetric,\n\u001B[1;32m   1528\u001B[0m     verbose_eval\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[1;32m   1529\u001B[0m     xgb_model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m   1530\u001B[0m     callbacks\u001B[38;5;241m=\u001B[39mcallbacks,\n\u001B[1;32m   1531\u001B[0m )\n\u001B[1;32m   1533\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobjective):\n\u001B[1;32m   1534\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobjective \u001B[38;5;241m=\u001B[39m params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mobjective\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/xgboost/core.py:730\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    728\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[1;32m    729\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[0;32m--> 730\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/xgboost/training.py:181\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001B[0m\n\u001B[1;32m    179\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cb_container\u001B[38;5;241m.\u001B[39mbefore_iteration(bst, i, dtrain, evals):\n\u001B[1;32m    180\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m--> 181\u001B[0m bst\u001B[38;5;241m.\u001B[39mupdate(dtrain, i, obj)\n\u001B[1;32m    182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cb_container\u001B[38;5;241m.\u001B[39mafter_iteration(bst, i, dtrain, evals):\n\u001B[1;32m    183\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/xgboost/core.py:2050\u001B[0m, in \u001B[0;36mBooster.update\u001B[0;34m(self, dtrain, iteration, fobj)\u001B[0m\n\u001B[1;32m   2047\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_assign_dmatrix_features(dtrain)\n\u001B[1;32m   2049\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fobj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 2050\u001B[0m     _check_call(\n\u001B[1;32m   2051\u001B[0m         _LIB\u001B[38;5;241m.\u001B[39mXGBoosterUpdateOneIter(\n\u001B[1;32m   2052\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle, ctypes\u001B[38;5;241m.\u001B[39mc_int(iteration), dtrain\u001B[38;5;241m.\u001B[39mhandle\n\u001B[1;32m   2053\u001B[0m         )\n\u001B[1;32m   2054\u001B[0m     )\n\u001B[1;32m   2055\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   2056\u001B[0m     pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict(dtrain, output_margin\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/xgboost/core.py:282\u001B[0m, in \u001B[0;36m_check_call\u001B[0;34m(ret)\u001B[0m\n\u001B[1;32m    271\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Check the return value of C API call\u001B[39;00m\n\u001B[1;32m    272\u001B[0m \n\u001B[1;32m    273\u001B[0m \u001B[38;5;124;03mThis function will raise exception when error occurs.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    279\u001B[0m \u001B[38;5;124;03m    return value from API calls\u001B[39;00m\n\u001B[1;32m    280\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    281\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ret \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 282\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m XGBoostError(py_str(_LIB\u001B[38;5;241m.\u001B[39mXGBGetLastError()))\n",
      "\u001B[0;31mXGBoostError\u001B[0m: [19:45:12] /Users/runner/work/xgboost/xgboost/src/metric/metric.cc:49: Unknown metric function binary:logistic\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x00000001697f0994 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n  [bt] (1) 2   libxgboost.dylib                    0x00000001699705c4 xgboost::Metric::Create(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, xgboost::Context const*) + 124\n  [bt] (2) 3   libxgboost.dylib                    0x00000001699461d8 xgboost::LearnerConfiguration::ConfigureMetrics(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 216\n  [bt] (3) 4   libxgboost.dylib                    0x00000001699381c8 xgboost::LearnerConfiguration::Configure() + 1072\n  [bt] (4) 5   libxgboost.dylib                    0x00000001699384b0 xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 128\n  [bt] (5) 6   libxgboost.dylib                    0x0000000169810ea4 XGBoosterUpdateOneIter + 144\n  [bt] (6) 7   libffi.8.dylib                      0x000000010337004c ffi_call_SYSV + 76\n  [bt] (7) 8   libffi.8.dylib                      0x000000010336d834 ffi_call_int + 1404\n  [bt] (8) 9   _ctypes.cpython-311-darwin.so       0x00000001030a8150 _ctypes_callproc + 752\n\n"
     ]
    }
   ],
   "source": [
    "close_data = df[['Close', 'X_t-1', 'X_t-2', 'X_t-3', 'RSI', 'Y_BUY']]\n",
    "x = close_data.drop(columns=['Y_BUY'])\n",
    "y = close_data[['Y_BUY']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "XGBOptimizer(x_train, y_train, x_test, y_test).xgb_optuna()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T01:45:13.092380Z",
     "start_time": "2024-03-07T01:45:12.511729Z"
    }
   },
   "id": "be332582de104f50"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4b7351d8609b7a34"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7bcedd6fd41cb6e0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
